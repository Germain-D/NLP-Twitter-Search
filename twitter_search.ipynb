{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7e33c0d617474e7089c4ae27abc584f2",
    "deepnote_cell_type": "text-cell-h1",
    "is_collapsed": false,
    "tags": []
   },
   "source": [
    "# Twitter search with word embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "a976a03b0343412197bbd2e9747fce14",
    "deepnote_cell_height": 74.80000305175781,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "Your task is to create a program that searches through twitter tweets using word embeddings. Given a search query, your program should return the top 5 tweets relating to this query for each distance algorithm used (you will use 2 distance algorithms, which means you'll return 10 tweets as a result. lore information below). You can achieve this by performing the following steps:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tabulate\n",
      "  Downloading tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: tabulate\n",
      "Successfully installed tabulate-0.8.9\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tabulate.exe is installed in 'C:\\Users\\germd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "WARNING: You are using pip version 21.2.4; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\germd\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "#pip install tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "cell_id": "a293f3357c0847fe812d8c6af57e0ced",
    "deepnote_cell_height": 339,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 6643,
    "execution_start": 1650895414917,
    "source_hash": "56bc0e91",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "cell_id": "225f63d6265b4c3ab25ce46dac4187ae",
    "deepnote_cell_height": 405,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 2,
    "execution_start": 1650898343016,
    "source_hash": "80b74b4c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import contractions\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "cell_id": "6eed36eeeb524c749b71049cf3458361",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 15,
    "execution_start": 1650893540539,
    "source_hash": "39164a21",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('tweets.csv', encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "cell_id": "9a6c69dbea6847b1aeba30ba5b4f515c",
    "deepnote_cell_height": 395,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 19,
    "execution_start": 1650893540573,
    "source_hash": "41313cfa",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>849636868052275200</td>\n",
       "      <td>2017-04-05 14:56:29</td>\n",
       "      <td>b'And so the robots spared humanity ... https:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>848988730585096192</td>\n",
       "      <td>2017-04-03 20:01:01</td>\n",
       "      <td>b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>848943072423497728</td>\n",
       "      <td>2017-04-03 16:59:35</td>\n",
       "      <td>b'@waltmossberg @mims @defcon_5 Et tu, Walt?'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>848935705057280001</td>\n",
       "      <td>2017-04-03 16:30:19</td>\n",
       "      <td>b'Stormy weather in Shortville ...'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>848416049573658624</td>\n",
       "      <td>2017-04-02 06:05:23</td>\n",
       "      <td>b\"@DaveLeeBBC @verge Coal is dying due to nat ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id           created_at  \\\n",
       "0  849636868052275200  2017-04-05 14:56:29   \n",
       "1  848988730585096192  2017-04-03 20:01:01   \n",
       "2  848943072423497728  2017-04-03 16:59:35   \n",
       "3  848935705057280001  2017-04-03 16:30:19   \n",
       "4  848416049573658624  2017-04-02 06:05:23   \n",
       "\n",
       "                                                text  \n",
       "0  b'And so the robots spared humanity ... https:...  \n",
       "1  b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exa...  \n",
       "2      b'@waltmossberg @mims @defcon_5 Et tu, Walt?'  \n",
       "3                b'Stormy weather in Shortville ...'  \n",
       "4  b\"@DaveLeeBBC @verge Coal is dying due to nat ...  "
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "56e1482a32ef4724a0c35cb0a22e77cc",
    "deepnote_cell_height": 52.399993896484375,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "1- Perform the necessary pre-processing on the tweets. Meep in mind that tweets contain lots of typos and non-conventional characters (like emoticons and the like).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "cell_id": "a93c4d2687f3499db0feaf52b83e24e9",
    "deepnote_cell_height": 495,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 4,
    "execution_start": 1650894211611,
    "source_hash": "b869f165",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    data_clean = data\n",
    "    data_clean['text_clean'] = data_clean['text']\n",
    "    \n",
    "    #remove first two characters\n",
    "    data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: x[2:])\n",
    "\n",
    "    #text to lowercase\n",
    "    data_clean['text_clean'] = data_clean['text_clean'].str.lower()\n",
    "\n",
    "    #remove URL links\n",
    "    data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: re.sub(r'https?:\\/\\/\\S+', '', x))\n",
    "    data_clean['text_clean'].apply(lambda x: re.sub(r\"www\\.[a-z]?\\.?(com)+|[a-z]+\\.(com)\", '', x))\n",
    "\n",
    "    #remove placeholders\n",
    "    data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: re.sub(r'{link}', '', x))\n",
    "    data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: re.sub(r\"\\[video\\]\", '', x))\n",
    "\n",
    "    #remove HTML reference characters\n",
    "    data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: re.sub(r'&[a-z]+;', '', x))\n",
    "\n",
    "    #remove handles\n",
    "    data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: re.sub(r\"@([a-zA-Z0-9_]{1,50})\",\"\", x))\n",
    "\n",
    "    #remove non-letter characters\n",
    "    data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x: re.sub(r\"[^a-z\\s\\(\\-:\\)\\\\\\/\\];='#]\", '', x))\n",
    "\n",
    "    # Replace contractions with their longer forms \n",
    "    data_clean['text_clean'] = data_clean['text_clean'].apply(lambda x:  contractions.fix(x))\n",
    "\n",
    " \n",
    "\n",
    "    return data_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "cell_id": "31a7c601ed2642f094bf9bdae90fdd31",
    "deepnote_cell_height": 81,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 34,
    "execution_start": 1650894515005,
    "source_hash": "ca6a96d6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_clean = clean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "cell_id": "aadf235828394a709a0265580eebdf07",
    "deepnote_cell_height": 503,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 219,
    "execution_start": 1650894581283,
    "source_hash": "40d37e33",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>849636868052275200</td>\n",
       "      <td>2017-04-05 14:56:29</td>\n",
       "      <td>b'And so the robots spared humanity ... https:...</td>\n",
       "      <td>and so the robots spared humanity</td>\n",
       "      <td>[and, so, the, robots, spared, humanity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>848988730585096192</td>\n",
       "      <td>2017-04-03 20:01:01</td>\n",
       "      <td>b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exa...</td>\n",
       "      <td>exactly tesla is absurdly overvalued if ba...</td>\n",
       "      <td>[exactly, tesla, is, absurdly, overvalued, if,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>848943072423497728</td>\n",
       "      <td>2017-04-03 16:59:35</td>\n",
       "      <td>b'@waltmossberg @mims @defcon_5 Et tu, Walt?'</td>\n",
       "      <td>et tu walt'</td>\n",
       "      <td>[et, tu, walt, ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>848935705057280001</td>\n",
       "      <td>2017-04-03 16:30:19</td>\n",
       "      <td>b'Stormy weather in Shortville ...'</td>\n",
       "      <td>stormy weather in shortville '</td>\n",
       "      <td>[stormy, weather, in, shortville, ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>848416049573658624</td>\n",
       "      <td>2017-04-02 06:05:23</td>\n",
       "      <td>b\"@DaveLeeBBC @verge Coal is dying due to nat ...</td>\n",
       "      <td>coal is dying due to nat gas fracking it is ...</td>\n",
       "      <td>[coal, is, dying, due, to, nat, gas, fracking,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id           created_at  \\\n",
       "0  849636868052275200  2017-04-05 14:56:29   \n",
       "1  848988730585096192  2017-04-03 20:01:01   \n",
       "2  848943072423497728  2017-04-03 16:59:35   \n",
       "3  848935705057280001  2017-04-03 16:30:19   \n",
       "4  848416049573658624  2017-04-02 06:05:23   \n",
       "\n",
       "                                                text  \\\n",
       "0  b'And so the robots spared humanity ... https:...   \n",
       "1  b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exa...   \n",
       "2      b'@waltmossberg @mims @defcon_5 Et tu, Walt?'   \n",
       "3                b'Stormy weather in Shortville ...'   \n",
       "4  b\"@DaveLeeBBC @verge Coal is dying due to nat ...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0                and so the robots spared humanity     \n",
       "1      exactly tesla is absurdly overvalued if ba...   \n",
       "2                                        et tu walt'   \n",
       "3                     stormy weather in shortville '   \n",
       "4    coal is dying due to nat gas fracking it is ...   \n",
       "\n",
       "                                              tokens  \n",
       "0           [and, so, the, robots, spared, humanity]  \n",
       "1  [exactly, tesla, is, absurdly, overvalued, if,...  \n",
       "2                                  [et, tu, walt, ']  \n",
       "3               [stormy, weather, in, shortville, ']  \n",
       "4  [coal, is, dying, due, to, nat, gas, fracking,...  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use the tweet tokenizer function from nltk (keep emojis)\n",
    "\n",
    "tknzr = TweetTokenizer()\n",
    "\n",
    "data_clean['tokens'] = data_clean['text_clean'].apply(tknzr.tokenize)\n",
    "\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "cell_id": "4cff540b8c464b05adbbae79c1565c56",
    "deepnote_cell_height": 575,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 241,
    "execution_start": 1650894778372,
    "source_hash": "4e103cb4",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>849636868052275200</td>\n",
       "      <td>2017-04-05 14:56:29</td>\n",
       "      <td>b'And so the robots spared humanity ... https:...</td>\n",
       "      <td>and so the robots spared humanity</td>\n",
       "      <td>[and, so, the, robots, spared, humanity]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>848988730585096192</td>\n",
       "      <td>2017-04-03 20:01:01</td>\n",
       "      <td>b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exa...</td>\n",
       "      <td>exactly tesla is absurdly overvalued if ba...</td>\n",
       "      <td>[exactly, tesla, is, absurdly, overvalued, if,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>848943072423497728</td>\n",
       "      <td>2017-04-03 16:59:35</td>\n",
       "      <td>b'@waltmossberg @mims @defcon_5 Et tu, Walt?'</td>\n",
       "      <td>et tu walt'</td>\n",
       "      <td>[et, tu, walt]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>848935705057280001</td>\n",
       "      <td>2017-04-03 16:30:19</td>\n",
       "      <td>b'Stormy weather in Shortville ...'</td>\n",
       "      <td>stormy weather in shortville '</td>\n",
       "      <td>[stormy, weather, in, shortville]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>848416049573658624</td>\n",
       "      <td>2017-04-02 06:05:23</td>\n",
       "      <td>b\"@DaveLeeBBC @verge Coal is dying due to nat ...</td>\n",
       "      <td>coal is dying due to nat gas fracking it is ...</td>\n",
       "      <td>[coal, is, dying, due, to, nat, gas, fracking,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id           created_at  \\\n",
       "0  849636868052275200  2017-04-05 14:56:29   \n",
       "1  848988730585096192  2017-04-03 20:01:01   \n",
       "2  848943072423497728  2017-04-03 16:59:35   \n",
       "3  848935705057280001  2017-04-03 16:30:19   \n",
       "4  848416049573658624  2017-04-02 06:05:23   \n",
       "\n",
       "                                                text  \\\n",
       "0  b'And so the robots spared humanity ... https:...   \n",
       "1  b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exa...   \n",
       "2      b'@waltmossberg @mims @defcon_5 Et tu, Walt?'   \n",
       "3                b'Stormy weather in Shortville ...'   \n",
       "4  b\"@DaveLeeBBC @verge Coal is dying due to nat ...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0                and so the robots spared humanity     \n",
       "1      exactly tesla is absurdly overvalued if ba...   \n",
       "2                                        et tu walt'   \n",
       "3                     stormy weather in shortville '   \n",
       "4    coal is dying due to nat gas fracking it is ...   \n",
       "\n",
       "                                              tokens  \n",
       "0           [and, so, the, robots, spared, humanity]  \n",
       "1  [exactly, tesla, is, absurdly, overvalued, if,...  \n",
       "2                                     [et, tu, walt]  \n",
       "3                  [stormy, weather, in, shortville]  \n",
       "4  [coal, is, dying, due, to, nat, gas, fracking,...  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove the punctuation to remove punctuation used for emojis\n",
    "\n",
    "PUNCUATION_LIST = list(string.punctuation)\n",
    "\n",
    "def remove_punctuation(word_list):\n",
    "    return [w for w in word_list if w not in PUNCUATION_LIST]\n",
    "    \n",
    "data_clean['tokens'] = data_clean['tokens'].apply(remove_punctuation)\n",
    "\n",
    "data_clean = data_clean.dropna()\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "b735ca69d1d949cea7a357f5abd7e919",
    "deepnote_cell_height": 97.19999694824219,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "2- Apply word embedding to the pre-processed tweets, using the GloVe model (choose the appropriate pre-trained model from here:  https://nlp.stanford.edu/projects/glove/  that conforms with your computer's processor capabilities; bigger model = more accuracy, and more memory requirements). The embedding representation of 1 tweet is the mean of the word embeddings of all the words in this tweet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global parameters\n",
    "#root folder\n",
    "root_folder='.'\n",
    "data_folder_name='glove.twitter.27B'\n",
    "\n",
    "#use the files you wanted\n",
    "glove_filename='glove.twitter.27B.200d.txt'\n",
    "\n",
    "\n",
    "# Variable for data directory\n",
    "DATA_PATH = os.path.abspath(os.path.join(root_folder, data_folder_name))\n",
    "glove_path = os.path.abspath(os.path.join(DATA_PATH, glove_filename))\n",
    "\n",
    "# Both train and test set are in the root data directory\n",
    "train_path = DATA_PATH\n",
    "test_path = DATA_PATH\n",
    "\n",
    "#Relevant columns\n",
    "TEXT_COLUMN = 'text'\n",
    "TARGET_COLUMN = 'target'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\germd\\AppData\\Local\\Temp/ipykernel_12560/1945688943.py:9: DeprecationWarning: Call to deprecated `glove2word2vec` (KeyedVectors.load_word2vec_format(.., binary=False, no_header=True) loads GLoVE text vectors.).\n",
      "  glove2word2vec(glove_path, word2vec_output_file)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1193514, 200)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We just need to run this code once, the function glove2word2vec saves the Glove embeddings in the word2vec format \n",
    "# that will be loaded in the next section\n",
    "\n",
    "glove_input_file = glove_filename\n",
    "word2vec_output_file = glove_filename+'.word2vec'\n",
    "\n",
    "glove2word2vec(glove_path, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Stanford GloVe model\n",
    "model = KeyedVectors.load_word2vec_format(word2vec_output_file, binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\germd\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\numpy\\core\\fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#vectorize tweets with our model\n",
    "def vectorize(tokenized_sentence):\n",
    "    result = []\n",
    "    for token in tokenized_sentence:\n",
    "        if(token in model.key_to_index):\n",
    "            result.append(model[token])\n",
    "    return np.mean(result, axis=0)\n",
    "\n",
    "\n",
    "data_clean['vectorized'] = data_clean['tokens'].apply(vectorize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "cell_id": "98a4ddc6c3544aa6ad66ea8abf407929",
    "deepnote_cell_height": 544.2000122070312,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     367
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 38,
    "execution_start": 1650898810451,
    "owner_user_id": "da547339-09a2-4a1a-82c5-d00e19e88d15",
    "source_hash": "b482da43",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vectorized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>849636868052275200</td>\n",
       "      <td>2017-04-05 14:56:29</td>\n",
       "      <td>b'And so the robots spared humanity ... https:...</td>\n",
       "      <td>and so the robots spared humanity</td>\n",
       "      <td>[and, so, the, robots, spared, humanity]</td>\n",
       "      <td>[0.16549633, 0.070804335, 0.17029466, 0.200102...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>848988730585096192</td>\n",
       "      <td>2017-04-03 20:01:01</td>\n",
       "      <td>b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exa...</td>\n",
       "      <td>exactly tesla is absurdly overvalued if ba...</td>\n",
       "      <td>[exactly, tesla, is, absurdly, overvalued, if,...</td>\n",
       "      <td>[0.17040388, 0.24164951, 0.22459331, 0.1952677...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>848943072423497728</td>\n",
       "      <td>2017-04-03 16:59:35</td>\n",
       "      <td>b'@waltmossberg @mims @defcon_5 Et tu, Walt?'</td>\n",
       "      <td>et tu walt'</td>\n",
       "      <td>[et, tu, walt]</td>\n",
       "      <td>[-0.021688962, -0.23816268, -0.389869, 0.24019...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>848935705057280001</td>\n",
       "      <td>2017-04-03 16:30:19</td>\n",
       "      <td>b'Stormy weather in Shortville ...'</td>\n",
       "      <td>stormy weather in shortville '</td>\n",
       "      <td>[stormy, weather, in, shortville]</td>\n",
       "      <td>[-0.33656335, -0.16922998, -0.48255336, -0.098...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>848416049573658624</td>\n",
       "      <td>2017-04-02 06:05:23</td>\n",
       "      <td>b\"@DaveLeeBBC @verge Coal is dying due to nat ...</td>\n",
       "      <td>coal is dying due to nat gas fracking it is ...</td>\n",
       "      <td>[coal, is, dying, due, to, nat, gas, fracking,...</td>\n",
       "      <td>[0.05625992, 0.012350748, -0.008011498, 0.0590...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id           created_at  \\\n",
       "0  849636868052275200  2017-04-05 14:56:29   \n",
       "1  848988730585096192  2017-04-03 20:01:01   \n",
       "2  848943072423497728  2017-04-03 16:59:35   \n",
       "3  848935705057280001  2017-04-03 16:30:19   \n",
       "4  848416049573658624  2017-04-02 06:05:23   \n",
       "\n",
       "                                                text  \\\n",
       "0  b'And so the robots spared humanity ... https:...   \n",
       "1  b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exa...   \n",
       "2      b'@waltmossberg @mims @defcon_5 Et tu, Walt?'   \n",
       "3                b'Stormy weather in Shortville ...'   \n",
       "4  b\"@DaveLeeBBC @verge Coal is dying due to nat ...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0                and so the robots spared humanity     \n",
       "1      exactly tesla is absurdly overvalued if ba...   \n",
       "2                                        et tu walt'   \n",
       "3                     stormy weather in shortville '   \n",
       "4    coal is dying due to nat gas fracking it is ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0           [and, so, the, robots, spared, humanity]   \n",
       "1  [exactly, tesla, is, absurdly, overvalued, if,...   \n",
       "2                                     [et, tu, walt]   \n",
       "3                  [stormy, weather, in, shortville]   \n",
       "4  [coal, is, dying, due, to, nat, gas, fracking,...   \n",
       "\n",
       "                                          vectorized  \n",
       "0  [0.16549633, 0.070804335, 0.17029466, 0.200102...  \n",
       "1  [0.17040388, 0.24164951, 0.22459331, 0.1952677...  \n",
       "2  [-0.021688962, -0.23816268, -0.389869, 0.24019...  \n",
       "3  [-0.33656335, -0.16922998, -0.48255336, -0.098...  \n",
       "4  [0.05625992, 0.012350748, -0.008011498, 0.0590...  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean = data_clean.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "7f699539ed554123b435d3886d792d00",
    "deepnote_cell_height": 228.8000030517578,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "\n",
    "3- Apply word embeddings to the search query.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'i want to go to the moon'"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#enter the sentence or word to see relevants tweets\n",
    "sentence = input()\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    i want to go to the moon\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#put sentence to a dataframe\n",
    "d = {'text': [sentence]}\n",
    "phrase = pd.DataFrame(data=d)\n",
    "phrase['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [i, want, to, go, to, the, moon]\n",
       "Name: tokens, dtype: object"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just tokenize the sentence\n",
    "tknzr = TweetTokenizer()\n",
    "phrase['tokens'] = phrase['text'].apply(tknzr.tokenize)\n",
    "phrase['tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.32468012, 0.21205099, 0.22474143, 0.0002394...\n",
       "Name: vectorized, dtype: object"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#and vectorized it\n",
    "phrase['vectorized'] = phrase['tokens'].apply(vectorize)\n",
    "phrase['vectorized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>tokens</th>\n",
       "      <th>vectorized</th>\n",
       "      <th>cosine</th>\n",
       "      <th>euclidian</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>849636868052275200</td>\n",
       "      <td>2017-04-05 14:56:29</td>\n",
       "      <td>b'And so the robots spared humanity ... https:...</td>\n",
       "      <td>and so the robots spared humanity</td>\n",
       "      <td>[and, so, the, robots, spared, humanity]</td>\n",
       "      <td>[0.16549633, 0.070804335, 0.17029466, 0.200102...</td>\n",
       "      <td>0.808744</td>\n",
       "      <td>3.747881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>848988730585096192</td>\n",
       "      <td>2017-04-03 20:01:01</td>\n",
       "      <td>b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exa...</td>\n",
       "      <td>exactly tesla is absurdly overvalued if ba...</td>\n",
       "      <td>[exactly, tesla, is, absurdly, overvalued, if,...</td>\n",
       "      <td>[0.17040388, 0.24164951, 0.22459331, 0.1952677...</td>\n",
       "      <td>0.838850</td>\n",
       "      <td>3.626420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>848943072423497728</td>\n",
       "      <td>2017-04-03 16:59:35</td>\n",
       "      <td>b'@waltmossberg @mims @defcon_5 Et tu, Walt?'</td>\n",
       "      <td>et tu walt'</td>\n",
       "      <td>[et, tu, walt]</td>\n",
       "      <td>[-0.021688962, -0.23816268, -0.389869, 0.24019...</td>\n",
       "      <td>0.434603</td>\n",
       "      <td>6.263538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>848935705057280001</td>\n",
       "      <td>2017-04-03 16:30:19</td>\n",
       "      <td>b'Stormy weather in Shortville ...'</td>\n",
       "      <td>stormy weather in shortville '</td>\n",
       "      <td>[stormy, weather, in, shortville]</td>\n",
       "      <td>[-0.33656335, -0.16922998, -0.48255336, -0.098...</td>\n",
       "      <td>0.635994</td>\n",
       "      <td>5.232181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>848416049573658624</td>\n",
       "      <td>2017-04-02 06:05:23</td>\n",
       "      <td>b\"@DaveLeeBBC @verge Coal is dying due to nat ...</td>\n",
       "      <td>coal is dying due to nat gas fracking it is ...</td>\n",
       "      <td>[coal, is, dying, due, to, nat, gas, fracking,...</td>\n",
       "      <td>[0.05625992, 0.012350748, -0.008011498, 0.0590...</td>\n",
       "      <td>0.803826</td>\n",
       "      <td>3.785735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id           created_at  \\\n",
       "0  849636868052275200  2017-04-05 14:56:29   \n",
       "1  848988730585096192  2017-04-03 20:01:01   \n",
       "2  848943072423497728  2017-04-03 16:59:35   \n",
       "3  848935705057280001  2017-04-03 16:30:19   \n",
       "4  848416049573658624  2017-04-02 06:05:23   \n",
       "\n",
       "                                                text  \\\n",
       "0  b'And so the robots spared humanity ... https:...   \n",
       "1  b\"@ForIn2020 @waltmossberg @mims @defcon_5 Exa...   \n",
       "2      b'@waltmossberg @mims @defcon_5 Et tu, Walt?'   \n",
       "3                b'Stormy weather in Shortville ...'   \n",
       "4  b\"@DaveLeeBBC @verge Coal is dying due to nat ...   \n",
       "\n",
       "                                          text_clean  \\\n",
       "0                and so the robots spared humanity     \n",
       "1      exactly tesla is absurdly overvalued if ba...   \n",
       "2                                        et tu walt'   \n",
       "3                     stormy weather in shortville '   \n",
       "4    coal is dying due to nat gas fracking it is ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0           [and, so, the, robots, spared, humanity]   \n",
       "1  [exactly, tesla, is, absurdly, overvalued, if,...   \n",
       "2                                     [et, tu, walt]   \n",
       "3                  [stormy, weather, in, shortville]   \n",
       "4  [coal, is, dying, due, to, nat, gas, fracking,...   \n",
       "\n",
       "                                          vectorized    cosine  euclidian  \n",
       "0  [0.16549633, 0.070804335, 0.17029466, 0.200102...  0.808744   3.747881  \n",
       "1  [0.17040388, 0.24164951, 0.22459331, 0.1952677...  0.838850   3.626420  \n",
       "2  [-0.021688962, -0.23816268, -0.389869, 0.24019...  0.434603   6.263538  \n",
       "3  [-0.33656335, -0.16922998, -0.48255336, -0.098...  0.635994   5.232181  \n",
       "4  [0.05625992, 0.012350748, -0.008011498, 0.0590...  0.803826   3.785735  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_clean.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "4- Calculate the distance between the embeddings of the search query and that of all the tweets, sort them in increasing order (smaller distance = more relevant to the search query). You will use 2 distance algorithms: cosine similarity and Euclidean distance. Both of these are implemented in scikit learn;\n",
    "Euclidian distance:  https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.euclidean_distances.html\n",
    "Cosine similarity: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.cosine_similarity.html\n",
    "After that, you return the top 5 tweets using each of the aforementioned search algorithms.\n",
    "\n",
    "The tweets dataset to be used is provided to this assignment.\n",
    "\n",
    "Your deliverable is a python notebook with all the code and necessary explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine similarity beetween vectorized sentence and vectorized tweets\n",
    "\n",
    "b = float(0)\n",
    "compt = 0\n",
    "cosi = []\n",
    "for i in data_clean.index:\n",
    "    cosi.append(float(cosine_similarity(phrase['vectorized'][0].reshape(1, -1),data_clean['vectorized'][i].reshape(1, -1))))\n",
    "    compt +=1\n",
    "data_clean['cosine'] = cosi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want to go to the moon\n",
      "+------+-----------------------------------------------------------------------------------------------------------------------------------------------+----------+\n",
      "|      | text                                                                                                                                          |   cosine |\n",
      "|------+-----------------------------------------------------------------------------------------------------------------------------------------------+----------|\n",
      "| 2816 | b'I made the volume on the Model S http://t.co/wMCnT53M go to 11.  Now I just need to work in a miniature Stonehenge...'                      | 0.965275 |\n",
      "| 1103 | b'@jpfrappier yes, will go all the way to Alaska'                                                                                             | 0.964836 |\n",
      "| 2454 | b\"To be super clear, I don't wish to (nor could I) mandate anything about a Mars Colony. Am just working on the tech to get people there.\"    | 0.963627 |\n",
      "| 1874 | b'@QuantumG When we launch I want to know that SpaceX has done everything possible to keep the astronauts safe. Only a few more years to go.' | 0.960352 |\n",
      "|  699 | b'We need to do one more minor rev on 8.0 and then will go to wide release in a few weeks'                                                    | 0.958175 |\n",
      "+------+-----------------------------------------------------------------------------------------------------------------------------------------------+----------+\n"
     ]
    }
   ],
   "source": [
    "#print the top 5 most relevant tweet with cosine similarity\n",
    "print(sentence)\n",
    "print(tabulate(data_clean[['text','cosine']].nlargest(5, ['cosine']), headers='keys', tablefmt='psql'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Euclidian Distance beetween vectorized sentence and vectorized tweets\n",
    "\n",
    "b = float(0)\n",
    "compt = 0\n",
    "eucl = []\n",
    "for i in data_clean.index:\n",
    "    eucl.append(float(euclidean_distances(phrase['vectorized'][0].reshape(1, -1),data_clean['vectorized'][i].reshape(1, -1))))\n",
    "    compt +=1\n",
    "data_clean['euclidian'] = eucl\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want to go to the moon\n",
      "+------+-----------------------------------------------------------------------------------------------------------------------------------------------+-------------+\n",
      "|      | text                                                                                                                                          |   euclidian |\n",
      "|------+-----------------------------------------------------------------------------------------------------------------------------------------------+-------------|\n",
      "| 1103 | b'@jpfrappier yes, will go all the way to Alaska'                                                                                             |     1.78927 |\n",
      "| 2816 | b'I made the volume on the Model S http://t.co/wMCnT53M go to 11.  Now I just need to work in a miniature Stonehenge...'                      |     1.87591 |\n",
      "| 2454 | b\"To be super clear, I don't wish to (nor could I) mandate anything about a Mars Colony. Am just working on the tech to get people there.\"    |     1.91583 |\n",
      "| 1874 | b'@QuantumG When we launch I want to know that SpaceX has done everything possible to keep the astronauts safe. Only a few more years to go.' |     1.96451 |\n",
      "|  565 | b'RT @jeffmason1: \"You almost want to get in and take off, don\\'t you?\" @POTUS says. https://t.co/DfAJOGyBWR'                                 |     1.99987 |\n",
      "+------+-----------------------------------------------------------------------------------------------------------------------------------------------+-------------+\n"
     ]
    }
   ],
   "source": [
    "#print the top 5 most relevant tweet with euclidian distance\n",
    "print(sentence)\n",
    "print(tabulate(data_clean[['text','euclidian']].nsmallest(5, ['euclidian']), headers='keys', tablefmt='psql'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exemple of result with the glove.twitter.27B.200d.txt file\n",
    "\n",
    "\"\"\"\n",
    "i want to go to the moon\n",
    "+------+-----------------------------------------------------------------------------------------------------------------------------------------------+-------------+\n",
    "|      | text                                                                                                                                          |   euclidian |\n",
    "|------+-----------------------------------------------------------------------------------------------------------------------------------------------+-------------|\n",
    "| 1103 | b'@jpfrappier yes, will go all the way to Alaska'                                                                                             |     1.78927 |\n",
    "| 2816 | b'I made the volume on the Model S http://t.co/wMCnT53M go to 11.  Now I just need to work in a miniature Stonehenge...'                      |     1.87591 |\n",
    "| 2454 | b\"To be super clear, I don't wish to (nor could I) mandate anything about a Mars Colony. Am just working on the tech to get people there.\"    |     1.91583 |\n",
    "| 1874 | b'@QuantumG When we launch I want to know that SpaceX has done everything possible to keep the astronauts safe. Only a few more years to go.' |     1.96451 |\n",
    "|  565 | b'RT @jeffmason1: \"You almost want to get in and take off, don\\'t you?\" @POTUS says. https://t.co/DfAJOGyBWR'                                 |     1.99987 |\n",
    "+------+-----------------------------------------------------------------------------------------------------------------------------------------------+-------------+\"\"\""
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "edd4d7be-33e7-4d16-8b22-7813182ef6d1",
  "interpreter": {
   "hash": "9665c213d0aa857773cb298a570f0030fcfd9cbd3896b1f79e332e6ff402f672"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
